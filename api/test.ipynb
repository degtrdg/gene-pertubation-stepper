{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "from datetime import datetime\n",
    "\n",
    "import diskcache\n",
    "from openai import OpenAI, AsyncOpenAI, OpenAIError\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "client = OpenAI(api_key=os.environ['OPENAI_API_KEY'])\n",
    "aclient = AsyncOpenAI()\n",
    "\n",
    "\n",
    "logs_dir = os.path.join(os.getcwd(), '.chatgpt_history/logs')\n",
    "cache_dir = os.path.join(os.getcwd(), '.chatgpt_history/cache')\n",
    "os.makedirs(logs_dir, exist_ok=True)\n",
    "os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "cache = diskcache.Cache(cache_dir)\n",
    "\n",
    "\n",
    "def get_key(messages):\n",
    "    return hashlib.sha256(json.dumps(messages, sort_keys=True).encode()).hexdigest()\n",
    "\n",
    "\n",
    "def retry_on_exception(retries=5, initial_wait_time=1):\n",
    "    def decorator(func):\n",
    "        if asyncio.iscoroutinefunction(func):\n",
    "            async def async_wrapper(*args, **kwargs):\n",
    "                wait_time = initial_wait_time\n",
    "                for attempt in range(retries):\n",
    "                    try:\n",
    "                        return await func(*args, **kwargs)\n",
    "                    except OpenAIError as e:\n",
    "                        if attempt == retries - 1:\n",
    "                            raise e\n",
    "                        print(e)\n",
    "                        await asyncio.sleep(wait_time)\n",
    "                        wait_time *= 2\n",
    "            return async_wrapper\n",
    "        else:\n",
    "            def sync_wrapper(*args, **kwargs):\n",
    "                wait_time = initial_wait_time\n",
    "                for attempt in range(retries):\n",
    "                    try:\n",
    "                        return func(*args, **kwargs)\n",
    "                    except OpenAIError as e:\n",
    "                        if attempt == retries - 1:\n",
    "                            raise e\n",
    "                        print(e)\n",
    "                        time.sleep(wait_time)\n",
    "                        wait_time *= 2\n",
    "            return sync_wrapper\n",
    "    return decorator\n",
    "\n",
    "\n",
    "@retry_on_exception()\n",
    "def complete(messages=None, model='gpt-4-turbo-preview', temperature=0, use_cache=True, **kwargs):\n",
    "    if use_cache:\n",
    "        key = get_key(messages)\n",
    "        if key in cache:\n",
    "            return cache.get(key)\n",
    "    response = client.chat.completions.create(\n",
    "        messages=messages, model=model, temperature=temperature, **kwargs)\n",
    "    return parse_response(response, messages, **kwargs)\n",
    "\n",
    "\n",
    "@retry_on_exception()\n",
    "async def acomplete(messages=None, model='gpt-4-turbo-preview', temperature=0, use_cache=True, **kwargs):\n",
    "    if use_cache:\n",
    "        key = get_key(messages)\n",
    "        if key in cache:\n",
    "            return cache.get(key)\n",
    "    response = aclient.chat.completions.create(messages=messages,\n",
    "                                                     model=model,\n",
    "                                                     temperature=temperature,\n",
    "                                                     **kwargs)\n",
    "    print(response)\n",
    "    print(type(response))\n",
    "    return parse_response(response, messages, **kwargs)\n",
    "\n",
    "\n",
    "def parse_response(response, messages, **kwargs):\n",
    "    n = kwargs.get('n', 1)\n",
    "    stream = kwargs.get('stream', False)\n",
    "    if stream:\n",
    "        strm = parse_stream(response, messages, n=n)\n",
    "        print(strm)\n",
    "        print(type(strm))\n",
    "        return strm\n",
    "\n",
    "    results = []\n",
    "    for choice in response.choices:\n",
    "        message = choice.message\n",
    "        if message.function_call:\n",
    "            name = message.function_call.name\n",
    "            try:\n",
    "                args = json.loads(message.function_call.arguments)\n",
    "            except json.decoder.JSONDecodeError as e:\n",
    "                print('ERROR: OpenAI returned invalid JSON for function call arguments')\n",
    "                raise e\n",
    "            results.append({'role': 'function', 'name': name, 'args': args})\n",
    "            log_completion(messages + [results[-1]])\n",
    "        else:\n",
    "            results.append(message.content)\n",
    "            log_completion(messages + [message])\n",
    "\n",
    "    output = results if n > 1 else results[0]\n",
    "    cache.set(get_key(messages), output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def parse_stream(response, messages, n=1):\n",
    "    results = ['' for _ in range(n)]\n",
    "    for chunk in response:\n",
    "        for choice in chunk.choices:\n",
    "            if not choice.delta:\n",
    "                continue\n",
    "            text = choice.delta.content\n",
    "            if not text:\n",
    "                continue\n",
    "            idx = choice.index\n",
    "            results[idx] += text\n",
    "            if n == 1:\n",
    "                yield text\n",
    "            else:\n",
    "                yield (text, idx)\n",
    "\n",
    "    for r in results:\n",
    "        log_completion(messages + [{'role': 'assistant', 'content': r}])\n",
    "    cache.set(get_key(messages), results)\n",
    "\n",
    "\n",
    "def log_completion(messages):\n",
    "    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S-%f')\n",
    "\n",
    "    save_path = os.path.join(logs_dir, timestamp + '.txt')\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "    log = \"\"\n",
    "    for message in messages:\n",
    "        if not isinstance(message, dict):\n",
    "            message = dict(message)\n",
    "            message = {k: v for k, v in message.items() if v is not None}\n",
    "\n",
    "        log += message['role'].upper() + ' ' + '-'*100 + '\\n\\n'\n",
    "        if 'name' in message:\n",
    "            log += f\"Called function: {message['name']}(\"\n",
    "            if 'args' in message:\n",
    "                log += '\\n'\n",
    "                for k, v in message['args'].items():\n",
    "                    log += f\"\\t{k}={repr(v)},\\n\"\n",
    "            log += ')'\n",
    "            if 'content' in message:\n",
    "                log += '\\nContent:\\n' + message['content']\n",
    "        elif 'function_call' in message:\n",
    "            log += f\"Called function: {message['function_call'].get('name', 'UNKNOWN')}(\\n\"\n",
    "            log += ')'\n",
    "        else:\n",
    "            log += message[\"content\"]\n",
    "        log += '\\n\\n'\n",
    "\n",
    "    with open(save_path, 'w') as f:\n",
    "        f.write(log)\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "# from .context_management import Context\n",
    "# from .structured2 import StructuredReasoner\n",
    "# from . import chatgpt\n",
    "# from context_management import Context\n",
    "# from structured2 import StructuredReasoner\n",
    "\n",
    "# class ProteinGraph:\n",
    "#     def __init__(self, info_file_path, links_file_path, start_protein):\n",
    "#         # Load protein information\n",
    "#         self.protein_info = pd.read_csv(\n",
    "#             # info_file_path, sep='\\t', compression='gzip')\n",
    "#             info_file_path, sep='\\t')\n",
    "\n",
    "#         # Load protein links\n",
    "#         self.protein_links = pd.read_csv(\n",
    "#             # links_file_path, sep=' ', compression='gzip')\n",
    "#             links_file_path, sep=' ')\n",
    "\n",
    "#         # Create a mapping from preferred names to protein IDs\n",
    "#         self.name_to_id = dict(\n",
    "#             zip(self.protein_info['preferred_name'], self.protein_info['#string_protein_id']))\n",
    "\n",
    "#         # Create a mapping from protein IDs to preferred names\n",
    "#         self.id_to_name = dict(\n",
    "#             zip(self.protein_info['#string_protein_id'], self.protein_info['preferred_name']))\n",
    "\n",
    "#         # Initialize an empty graph\n",
    "#         self.graph = nx.Graph()\n",
    "\n",
    "#         self.start_protein = start_protein\n",
    "\n",
    "#     def get_interacting_proteins(self, protein_name):\n",
    "#         if protein_name not in self.name_to_id:\n",
    "#             return f\"Protein '{protein_name}' not found in the dataset.\"\n",
    "\n",
    "#         protein_id = self.name_to_id[protein_name]\n",
    "\n",
    "#         # Filter interactions involving the protein of interest\n",
    "#         interacting_proteins = self.protein_links[\n",
    "#             (self.protein_links['protein1'] == protein_id) |\n",
    "#             (self.protein_links['protein2'] == protein_id)\n",
    "#         ]\n",
    "\n",
    "#         # Flip the proteins if necessary\n",
    "#         def flip_proteins(row, target_protein):\n",
    "#             if row['protein2'] == target_protein:\n",
    "#                 return row['protein2'], row['protein1'], row['combined_score']\n",
    "#             return row['protein1'], row['protein2'], row['combined_score']\n",
    "\n",
    "#         # Apply the flip_proteins function and explicitly cast the 'combined_score' to float to avoid dtype incompatibility issues\n",
    "#         flipped_proteins = interacting_proteins.apply(\n",
    "#             lambda row: flip_proteins(row, protein_id), axis=1, result_type='expand')\n",
    "#         interacting_proteins['protein1'] = flipped_proteins[0]\n",
    "#         interacting_proteins['protein2'] = flipped_proteins[1]\n",
    "#         interacting_proteins['combined_score'] = flipped_proteins[2].astype(\n",
    "#             float)\n",
    "\n",
    "#         # Group by protein pairs and keep the interaction with the highest score\n",
    "#         interacting_proteins = interacting_proteins.groupby(\n",
    "#             ['protein1', 'protein2'], as_index=False\n",
    "#         ).agg({'combined_score': 'max'})\n",
    "\n",
    "#         # Map protein IDs to their preferred names\n",
    "#         interacting_proteins['protein1'] = interacting_proteins['protein1'].map(\n",
    "#             self.id_to_name)\n",
    "#         interacting_proteins['protein2'] = interacting_proteins['protein2'].map(\n",
    "#             self.id_to_name)\n",
    "\n",
    "#         # Sort by combined_score in descending order before returning\n",
    "#         interacting_proteins = interacting_proteins.sort_values(\n",
    "#             by='combined_score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "#         # Return the dataframe with protein names instead of IDs\n",
    "#         return interacting_proteins\n",
    "\n",
    "#     def get_protein_info(self, protein_name):\n",
    "#         if protein_name not in self.name_to_id:\n",
    "#             return f\"Protein '{protein_name}' not found in the dataset.\"\n",
    "\n",
    "#         protein_id = self.name_to_id[protein_name]\n",
    "#         return self.protein_info[self.protein_info['#string_protein_id'] == protein_id]\n",
    "\n",
    "#     def get_protein_info_by_id(self, protein_id):\n",
    "#         return self.protein_info[self.protein_info['#string_protein_id'] == protein_id]\n",
    "\n",
    "#     def explore_protein(self, protein_name=None, top_n=5):\n",
    "#         if protein_name is None:\n",
    "#             if not self.graph.nodes:\n",
    "#                 print(\"No starting protein specified.\")\n",
    "#                 return\n",
    "\n",
    "#             # Find all leaf nodes (nodes with degree 1)\n",
    "#             leaf_nodes = [node for node,\n",
    "#                           degree in self.graph.degree() if degree == 1]\n",
    "\n",
    "#             # If there are no leaf nodes, end the function\n",
    "#             if not leaf_nodes:\n",
    "#                 print(\"No leaf nodes to explore from current graph.\")\n",
    "#                 return\n",
    "\n",
    "#             # Calculate the depth of each leaf node from 'ARF5' and sort them\n",
    "#             leaf_nodes_depth = {node: nx.shortest_path_length(\n",
    "#                 self.graph, source=self.start_protein, target=node) for node in leaf_nodes}\n",
    "#             # Sort the leaf nodes by depth (or any other criteria you have)\n",
    "#             sorted_leaf_nodes = sorted(\n",
    "#                 leaf_nodes_depth, key=leaf_nodes_depth.get)\n",
    "\n",
    "#             # Get the leaf node with the highest depth (or other criteria)\n",
    "#             protein_name = sorted_leaf_nodes[-1]\n",
    "\n",
    "#         # Add node and edges for the specified protein name\n",
    "#         edges = self.add_protein_and_edges(protein_name, top_n)\n",
    "#         return protein_name, edges\n",
    "\n",
    "#     def add_protein_and_edges(self, protein_name, top_n):\n",
    "#         if protein_name not in self.name_to_id:\n",
    "#             print(f\"Protein '{protein_name}' not found in the dataset.\")\n",
    "#             return\n",
    "\n",
    "#         # Get interacting proteins, map to names, and sort by score\n",
    "#         potential_edges = self.get_interacting_proteins(\n",
    "#             protein_name).head(top_n)\n",
    "\n",
    "#         # Add edges to the graph\n",
    "#         for _, row in potential_edges.iterrows():\n",
    "#             self.graph.add_edge(\n",
    "#                 row['protein1'], row['protein2'], weight=row['combined_score'])\n",
    "\n",
    "#         return potential_edges\n",
    "\n",
    "#     def visualize_graph(self):\n",
    "#         plt.figure(figsize=(10, 10))\n",
    "#         # Positioning the nodes using the spring layout\n",
    "#         pos = nx.spring_layout(self.graph, seed=42)\n",
    "#         nx.draw(self.graph, pos, with_labels=True, node_color='skyblue',\n",
    "#                 node_size=2000, font_size=10, font_weight='bold')\n",
    "#         labels = nx.get_edge_attributes(self.graph, 'weight')\n",
    "#         nx.draw_networkx_edge_labels(self.graph, pos, edge_labels=labels)\n",
    "#         plt.title(\"Protein Interaction Graph\")\n",
    "#         plt.show()\n",
    "\n",
    "#     def get_graph_data_for_visualization(self):\n",
    "#         # Convert the networkx graph into a format suitable for D3.js\n",
    "#         nodes = [{\"id\": node, \"label\": node} for node in self.graph.nodes()]\n",
    "#         edges = [{\"source\": u, \"target\": v, \"weight\": d[\"weight\"]}\n",
    "#                  for u, v, d in self.graph.edges(data=True)]\n",
    "#         return nodes, edges\n",
    "\n",
    "\n",
    "# class ProteinExplorerAgent:\n",
    "#     def __init__(self, protein_graph: ProteinGraph, start_protein, start_interaction, stopping_condition, model='gpt-4'):\n",
    "#         self.protein_graph = protein_graph\n",
    "#         self.current_protein = start_protein\n",
    "#         self.start_protein = start_protein\n",
    "#         self.start_interaction = start_interaction\n",
    "#         self.stopping_condition = stopping_condition\n",
    "#         self.model = model\n",
    "#         self.context = Context()\n",
    "#         self.system_prompt = self.clean_indent(\"\"\"\n",
    "#             You are a gene perturbation simulator for human cells. You are exploring the effects of perturbing genes in a protein interaction network. You will base your analyses with respect to information and conclusions you have seen so far.\n",
    "#             \"\"\")\n",
    "#         self.reasoner = StructuredReasoner(\n",
    "#             system_prompt=self.system_prompt, model=self.model)\n",
    "#         self.explored_proteins = set()\n",
    "\n",
    "#     def start(self, start_protein, edges):\n",
    "#         # Add initial message about the start protein\n",
    "#         self.context.add_message('system', self.system_prompt, idx=0)\n",
    "#         prompt = self.clean_indent(f\"\"\"\n",
    "#         ```md\n",
    "#         {self.get_gene_description([start_protein, *edges['protein2']])}\n",
    "#         ```\n",
    "#         {start_protein} has been {self.start_interaction}\n",
    "#         Simulate what happens on the whole and what happens to the other genes in its network which include {', '.join(edges['protein2'])}\n",
    "#         \"\"\")\n",
    "#         self.context.add_message('user', prompt)\n",
    "#         return acomplete(self.context.messages, model=self.model, stream=True)\n",
    "\n",
    "#     def get_gene_description(self, gene):\n",
    "#         if isinstance(gene, list):\n",
    "#             descriptions = []\n",
    "#             for g in gene:\n",
    "#                 annotation = self.protein_graph.get_protein_info(g)[\n",
    "#                     'annotation'].iloc[0]\n",
    "#                 descriptions.append(f\"gene: {g}\\n{annotation}\\n\")\n",
    "#             return \"\\n\".join(descriptions)\n",
    "#         else:\n",
    "#             annotation = self.protein_graph.get_protein_info(gene)[\n",
    "#                 'annotation'].iloc[0]\n",
    "#             return f\"gene: {gene}\\n{annotation}\\n\"\n",
    "\n",
    "#     def explore(self, start_protein=None):\n",
    "#         next_protein, edges = self.protein_graph.explore_protein(\n",
    "#             protein_name=start_protein)\n",
    "#         if next_protein in self.explored_proteins:\n",
    "#             return None, None\n",
    "#         self.current_protein = next_protein\n",
    "#         self.explored_proteins.add(next_protein)\n",
    "#         return next_protein, edges\n",
    "\n",
    "#     def simulate_change(self, next_protein, edges):\n",
    "#         sim = self.simulate_state_change(next_protein, edges)\n",
    "#         return sim\n",
    "\n",
    "#     async def simulate_state_change(self, protein, edges):\n",
    "#         # Use the reasoner to simulate the state change for the protein\n",
    "#         prompt = self.clean_indent(f\"\"\"\n",
    "#         ```md\n",
    "#         {self.get_gene_description([protein, *edges['protein2']])}\n",
    "#         ```\n",
    "#         We're going to look specifically at {protein} with respect to the previous context.\n",
    "#         These are the genes in its network:\n",
    "#         {', '.join(edges['protein2'])}\n",
    "#         Simulate what is happening to the whole and what happens to the other genes in its network.\n",
    "#         \"\"\")\n",
    "#         self.context.add_message('user', prompt)\n",
    "#         ret = acomplete(self.context.messages,\n",
    "#                                 model=self.model, stream=True)\n",
    "#         print(ret)\n",
    "#         print(type(ret))\n",
    "#         ret2 = await acomplete(self.context.messages,\n",
    "#                                        model=self.model, stream=True)\n",
    "#         print(ret2)\n",
    "#         print(type(ret2))\n",
    "\n",
    "#         return ret\n",
    "\n",
    "#     def check_for_condition(self):\n",
    "#         # Use the reasoner to check if the state change causes damage\n",
    "#         self.reasoner.messages = self.context.messages\n",
    "#         self.reasoner.add_message(\n",
    "#             'user', f'Has the current analysis shown whether the state has reached the condition \"{self.stopping_condition}\"?')\n",
    "#         answer = self.reasoner.extract_info(\n",
    "#             'The condition has not been reached: {answer}', bool)\n",
    "#         return answer\n",
    "\n",
    "#     def clean_indent(self, s):\n",
    "#         return '\\n'.join([line.lstrip() for line in s.split('\\n')]).strip()\n",
    "\n",
    "\n",
    "def printj(json_obj):\n",
    "    print(json.dumps(json_obj, indent=4))\n",
    "\n",
    "\n",
    "def clean_indent(s):\n",
    "    return '\\n'.join([line.lstrip() for line in s.split('\\n')])\n",
    "\n",
    "# info_file_path = '/Users/danielgeorge/Documents/work/bio/futurehouse/gene_stepper/graph_db/9606.protein.info.v12.0.txt.gz'\n",
    "# links_file_path = '/Users/danielgeorge/Documents/work/bio/futurehouse/gene_stepper/graph_db/9606.protein.links.v12.0.txt.gz'\n",
    "info_file_path = '/Users/danielgeorge/Documents/work/bio/futurehouse/gene_stepper/graph_db/9606.protein.info.v12.0.txt'\n",
    "links_file_path = '/Users/danielgeorge/Documents/work/bio/futurehouse/gene_stepper/graph_db/9606.protein.links.v12.0.txt'\n",
    "# protein_graph = ProteinGraph(\n",
    "#     info_file_path, links_file_path, start_protein='ARF5')\n",
    "# protein_explorer = ProteinExplorerAgent(\n",
    "#     protein_graph, start_protein='ARF5', start_interaction='knocked out', stopping_condition='apoptosis')\n",
    "# start_protein, edges = protein_explorer.explore(\n",
    "#     start_protein='ARF5')\n",
    "# start = protein_explorer.start(start_protein=start_protein, edges=edges)\n",
    "# print(start)\n",
    "# # import asyncio\n",
    "\n",
    "# # asyncio.run(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m generate_responses([{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is the gene description for ARF5?\u001b[39m\u001b[38;5;124m'\u001b[39m}]):\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[0;32m---> 48\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/311/lib/python3.11/asyncio/runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "@retry_on_exception()\n",
    "async def acomplete(messages=None, model='gpt-4-turbo-preview', temperature=0, use_cache=True, **kwargs):\n",
    "    if use_cache:\n",
    "        key = get_key(messages)\n",
    "        if key in cache:\n",
    "            yield cache.get(key)\n",
    "    response = await aclient.chat.completions.create(messages=messages,\n",
    "                                                     model=model,\n",
    "                                                     temperature=temperature,\n",
    "                                                     **kwargs)\n",
    "    async for item in parse_stream(response, messages, n=kwargs.get('n', 1)):\n",
    "        yield item\n",
    "\n",
    "async def parse_stream(response, messages, n=1):\n",
    "    results = ['' for _ in range(n)]\n",
    "    async for chunk in response:\n",
    "        for choice in chunk.choices:\n",
    "            if not choice.delta:\n",
    "                continue\n",
    "            text = choice.delta.content\n",
    "            if not text:\n",
    "                continue\n",
    "            idx = choice.index\n",
    "            results[idx] += text\n",
    "            if n == 1:\n",
    "                yield text\n",
    "            else:\n",
    "                yield (text, idx)\n",
    "\n",
    "    for r in results:\n",
    "        log_completion(messages + [{'role': 'assistant', 'content': r}])\n",
    "    cache.set(get_key(messages), results)\n",
    "\n",
    "# Usage\n",
    "async def generate_responses(messages):\n",
    "    # data = acomplete(, model='gpt-4-turbo-preview', stream=True)\n",
    "    data = aclient.chat.completions.create(messages=[{'role': 'user', 'content': 'What is the gene description for ARF5?'}],\n",
    "                                      model='gpt-3.5-turbo',\n",
    "                                      temperature=0,\n",
    "                                      stream=True)\n",
    "    async for d in data:\n",
    "        yield d\n",
    "\n",
    "async def main():\n",
    "    async for response in generate_responses([{'role': 'user', 'content': 'What is the gene description for ARF5?'}]):\n",
    "        print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    next_protein, edges = protein_explorer.explore()\n",
    "    print(next_protein)\n",
    "    sim = protein_explorer.simulate_change(next_protein, edges)\n",
    "    print(sim)\n",
    "    answer = protein_explorer.check_for_condition()\n",
    "    print(f'condition of apoptosis reached: {answer}')\n",
    "    protein_graph.visualize_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
